[2022-04-03 17:57:57,819] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: pandas_python_operator.get_dataframe manual__2022-04-03T22:57:48.723293+00:00 [queued]>
[2022-04-03 17:57:58,066] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: pandas_python_operator.get_dataframe manual__2022-04-03T22:57:48.723293+00:00 [queued]>
[2022-04-03 17:57:58,066] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-04-03 17:57:58,066] {taskinstance.py:1244} INFO - Starting attempt 1 of 1
[2022-04-03 17:57:58,066] {taskinstance.py:1245} INFO - 
--------------------------------------------------------------------------------
[2022-04-03 17:57:58,504] {taskinstance.py:1264} INFO - Executing <Task(_PythonDecoratedOperator): get_dataframe> on 2022-04-03 22:57:48.723293+00:00
[2022-04-03 17:57:58,532] {standard_task_runner.py:52} INFO - Started process 9842 to run task
[2022-04-03 17:57:58,540] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'pandas_python_operator', 'get_dataframe', 'manual__2022-04-03T22:57:48.723293+00:00', '--job-id', '301', '--raw', '--subdir', 'DAGS_FOLDER/procesar_datos_uni_villa_maria.py', '--cfg-path', '/tmp/tmp2hsqyqwn', '--error-file', '/tmp/tmpst66p1s0']
[2022-04-03 17:57:58,542] {standard_task_runner.py:77} INFO - Job 301: Subtask get_dataframe
[2022-04-03 17:57:58,777] {logging_mixin.py:109} INFO - Running <TaskInstance: pandas_python_operator.get_dataframe manual__2022-04-03T22:57:48.723293+00:00 [running]> on host LAPTOP-5HJG55H7.localdomain
[2022-04-03 17:57:59,272] {taskinstance.py:1429} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=pandas_python_operator
AIRFLOW_CTX_TASK_ID=get_dataframe
AIRFLOW_CTX_EXECUTION_DATE=2022-04-03T22:57:48.723293+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-04-03T22:57:48.723293+00:00
[2022-04-03 17:57:59,289] {base.py:70} INFO - Using connection to: id: airflow-universities. Host: training-main.cghe7e6sfljt.us-east-1.rds.amazonaws.com, Port: 5432, Schema: training, Login: alkymer, Password: ***, extra: {}
[2022-04-03 17:58:01,410] {procesar_datos_uni_villa_maria.py:98} INFO - Got dataframe
[2022-04-03 17:58:01,410] {python.py:175} INFO - Done. Returned value was:                             university  ...                          email
0  UNIVERSIDAD_NACIONAL_DE_VILLA_MARÍA  ...          RICHARD21@HOTMAIL.COM
1  UNIVERSIDAD_NACIONAL_DE_VILLA_MARÍA  ...            JDALTON@HOTMAIL.COM
2  UNIVERSIDAD_NACIONAL_DE_VILLA_MARÍA  ...            JUANMAY@HOTMAIL.COM
3  UNIVERSIDAD_NACIONAL_DE_VILLA_MARÍA  ...              ITORRES@YAHOO.COM
4  UNIVERSIDAD_NACIONAL_DE_VILLA_MARÍA  ...  TIFFANYWASHINGTON@HOTMAIL.COM

[5 rows x 8 columns]
[2022-04-03 17:58:01,553] {xcom.py:447} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config.
[2022-04-03 17:58:01,553] {taskinstance.py:1718} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1519, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2145, in xcom_push
    XCom.set(
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/xcom.py", line 155, in set
    value=cls.serialize_value(value),
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/xcom.py", line 445, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/lib/python3.8/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2022-04-03 17:58:01,569] {taskinstance.py:1272} INFO - Marking task as FAILED. dag_id=pandas_python_operator, task_id=get_dataframe, execution_date=20220403T225748, start_date=20220403T225757, end_date=20220403T225801
[2022-04-03 17:58:02,366] {standard_task_runner.py:89} ERROR - Failed to execute job 301 for task get_dataframe
Traceback (most recent call last):
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1519, in _execute_task
    self.xcom_push(key=XCOM_RETURN_KEY, value=result)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2145, in xcom_push
    XCom.set(
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/xcom.py", line 155, in set
    value=cls.serialize_value(value),
  File "/home/lowenhard/acceleration/env/lib/python3.8/site-packages/airflow/models/xcom.py", line 445, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/lib/python3.8/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type DataFrame is not JSON serializable
[2022-04-03 17:58:02,388] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-04-03 17:58:02,590] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
